# EAI_04 - NLP Cl√°ssico

M√≥dulo completo de **Processamento de Linguagem Natural Cl√°ssico**, cobrindo fundamentos (pr√©-processamento, TF-IDF, embeddings), modelos tradicionais de ML e projetos deployados em produ√ß√£o.

---

## üéØ Objetivo do M√≥dulo

Dominar t√©cnicas cl√°ssicas de NLP que s√£o **base essencial** para:
- ‚úÖ Entender sistemas modernos (BERT, GPT)
- ‚úÖ Construir baselines r√°pidos e eficientes
- ‚úÖ Deployar modelos leves em produ√ß√£o
- ‚úÖ Resolver 80% dos problemas de NLP com ferramentas simples

**Por que estudar NLP Cl√°ssico em 2026?**
- Modelos pequenos e r√°pidos (deploy f√°cil)
- Menor custo computacional (CPU √© suficiente)
- Mais interpret√°veis (sabe por que o modelo decide)
- Ainda muito usados em produ√ß√£o real

---

## üìÇ Estrutura do M√≥dulo

```
EAI_04_NLP_Classico/
‚îú‚îÄ‚îÄ README.md (este arquivo)
‚îú‚îÄ‚îÄ AGENT_CONTEXT.md
‚îÇ
‚îú‚îÄ‚îÄ Fundamentos/                    # 6 notebooks
‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ AGENT_CONTEXT.md
‚îÇ   ‚îú‚îÄ‚îÄ pre_processamento_texto.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ bow_tfidf.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ representacao_bow_tfidf.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ word_embeddings.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ pretrained_embeddings.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ analise_sentimentos.ipynb
‚îÇ
‚îú‚îÄ‚îÄ Modelos_Base/                   # 3 notebooks
‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ AGENT_CONTEXT.md
‚îÇ   ‚îú‚îÄ‚îÄ naive_bayes_sentimentos.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ classificacao_texto_svm.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ comparativo_tfidf_vs_embeddings.ipynb
‚îÇ
‚îî‚îÄ‚îÄ Projetos/                       # 2 aplica√ß√µes
    ‚îú‚îÄ‚îÄ Analise_de_Feedback/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ AGENT_CONTEXT.md
    ‚îÇ   ‚îú‚îÄ‚îÄ app.py (Flask)
    ‚îÇ   ‚îú‚îÄ‚îÄ notebook/
    ‚îÇ   ‚îú‚îÄ‚îÄ models/
    ‚îÇ   ‚îú‚îÄ‚îÄ templates/
    ‚îÇ   ‚îî‚îÄ‚îÄ static/
    ‚îÇ
    ‚îî‚îÄ‚îÄ Sistema_de_Busca_FAQs/
        ‚îú‚îÄ‚îÄ README.md
        ‚îú‚îÄ‚îÄ AGENT_CONTEXT.md
        ‚îú‚îÄ‚îÄ app.py (Flask)
        ‚îú‚îÄ‚îÄ notebook/
        ‚îú‚îÄ‚îÄ models/
        ‚îú‚îÄ‚îÄ templates/
        ‚îî‚îÄ‚îÄ static/
```

**Total**: 12 arquivos de documenta√ß√£o + 9 notebooks + 2 projetos deployados

---

## üó∫Ô∏è Jornada de Aprendizado

### Trilha Completa (Recomendado)

#### Semana 1: Fundamentos (6 notebooks)
```
Dia 1-2: Pr√©-processamento e BoW/TF-IDF
  ‚îî‚îÄ pre_processamento_texto.ipynb
  ‚îî‚îÄ bow_tfidf.ipynb

Dia 3-4: TF-IDF Avan√ßado e Aplica√ß√£o
  ‚îî‚îÄ representacao_bow_tfidf.ipynb
  ‚îî‚îÄ analise_sentimentos.ipynb

Dia 5-6: Word Embeddings
  ‚îî‚îÄ word_embeddings.ipynb
  ‚îî‚îÄ pretrained_embeddings.ipynb
```

#### Semana 2: Modelos Base (3 notebooks)
```
Dia 1-2: Naive Bayes
  ‚îî‚îÄ naive_bayes_sentimentos.ipynb

Dia 3-4: SVM
  ‚îî‚îÄ classificacao_texto_svm.ipynb

Dia 5-6: Compara√ß√£o
  ‚îî‚îÄ comparativo_tfidf_vs_embeddings.ipynb
```

#### Semana 3-4: Projetos (2 aplica√ß√µes)
```
Semana 3: An√°lise de Feedback
  ‚îî‚îÄ Estudo do c√≥digo
  ‚îî‚îÄ Execu√ß√£o local
  ‚îî‚îÄ Adapta√ß√£o para seus dados

Semana 4: Sistema de Busca FAQs
  ‚îî‚îÄ Estudo do c√≥digo
  ‚îî‚îÄ Execu√ß√£o local
  ‚îî‚îÄ Experimenta√ß√£o
```

---

### Trilha R√°pida (1 semana)

Para quem j√° tem experi√™ncia com ML:

```
Dia 1: Fundamentos essenciais
  ‚îî‚îÄ bow_tfidf.ipynb
  ‚îî‚îÄ word_embeddings.ipynb

Dia 2-3: Modelos
  ‚îî‚îÄ naive_bayes_sentimentos.ipynb
  ‚îî‚îÄ classificacao_texto_svm.ipynb

Dia 4-5: Compara√ß√£o e Projetos
  ‚îî‚îÄ comparativo_tfidf_vs_embeddings.ipynb
  ‚îî‚îÄ Executar os 2 projetos
```

---

## üìö Conte√∫do Detalhado

### 1Ô∏è‚É£ Fundamentos (Teoria + Pr√°tica)

#### üîß pre_processamento_texto.ipynb
- Limpeza de texto (lowercase, pontua√ß√£o)
- Stopwords e remo√ß√£o
- Stemming vs Lemmatization
- Pipeline completo reutiliz√°vel

#### üìä bow_tfidf.ipynb
- Bag of Words (contagem)
- TF-IDF (import√¢ncia)
- Compara√ß√£o lado a lado
- F√≥rmulas matem√°ticas

#### üìà representacao_bow_tfidf.ipynb
- N-gramas (uni, bi, tri)
- Par√¢metros (max_df, min_df, max_features)
- Normaliza√ß√£o L2
- Otimiza√ß√£o de vocabul√°rio

#### üß† word_embeddings.ipynb
- Word2Vec (CBOW vs Skip-gram)
- FastText (subpalavras)
- Treinamento do zero
- Aritm√©tica sem√¢ntica (rei - homem + mulher ‚âà rainha)

#### üíé pretrained_embeddings.ipynb
- NILC Word2Vec (portugu√™s)
- GloVe (ingl√™s)
- Como usar em modelos
- Vantagens vs treinar do zero

#### üéØ analise_sentimentos.ipynb
- Pipeline end-to-end
- TF-IDF + Logistic Regression
- Classifica√ß√£o Positivo/Negativo
- Aplica√ß√£o pr√°tica completa

---

### 2Ô∏è‚É£ Modelos Base (Templates Prontos)

#### üöÄ naive_bayes_sentimentos.ipynb
**Modelo**: Multinomial Naive Bayes  
**Performance**: ~85-88% accuracy  
**Quando usar**: Baseline r√°pido, poucos dados

```python
Pipeline([
    ('tfidf', TfidfVectorizer(max_features=5000)),
    ('nb', MultinomialNB(alpha=1.0))
])
```

#### ‚ö° classificacao_texto_svm.ipynb
**Modelo**: LinearSVC  
**Performance**: ~89-92% accuracy  
**Quando usar**: Melhor performance, produ√ß√£o

```python
Pipeline([
    ('tfidf', TfidfVectorizer(
        max_features=10000,
        ngram_range=(1,2)
    )),
    ('svm', LinearSVC(C=1.0))
])
```

#### üî¨ comparativo_tfidf_vs_embeddings.ipynb
**Experimento**: 3 abordagens comparadas  
**Resultado t√≠pico**:
- TF-IDF: ~87%
- Word2Vec pr√≥prio: ~85%
- Embeddings pr√©-treinados: ~90% ‚≠ê

---

### 3Ô∏è‚É£ Projetos (Aplica√ß√µes Reais)

#### üìä Projeto 1: An√°lise de Feedback

**Problema**: Classificar feedbacks automaticamente  
**Solu√ß√£o**: 2 modelos especializados

**Modelo 1 - Sentimento**:
- Positivo vs Negativo
- Dataset: B2W-Reviews (129k)
- Accuracy: 95%

**Modelo 2 - Sugest√£o**:
- Cont√©m sugest√£o de melhoria?
- Dataset: Sugest√µes IA (3k)
- Accuracy: 98%

**Deploy**: Flask web app  
**Diferencial**: Dupla classifica√ß√£o > modelo √∫nico

---

#### üîç Projeto 2: Sistema de Busca FAQs

**Problema**: Buscar FAQs por significado (n√£o palavras exatas)  
**Solu√ß√£o**: Busca sem√¢ntica com Sentence Transformers

**Tecnologia**:
- Modelo: distiluse-base-multilingual-cased-v1
- M√©todo: Similaridade de cosseno
- Dataset: 1.172 FAQs do Banco Central

**Performance**:
- Top-1 Accuracy: ~75%
- Top-3 Accuracy: ~90%
- Velocidade: <1s

**Deploy**: Flask web app  
**Diferencial**: Entende sin√¥nimos e contexto

---

## üìä Compara√ß√£o de T√©cnicas

### Representa√ß√µes de Texto

| T√©cnica | Dimens√µes | Tipo | Sem√¢ntica | Quando Usar |
|---------|-----------|------|-----------|-------------|
| **BoW** | 10k-100k | Esparso | ‚ùå | Baseline r√°pido |
| **TF-IDF** | 10k-100k | Esparso | ‚ùå | Classifica√ß√£o, busca |
| **Word2Vec** | 100-300 | Denso | ‚úÖ | Similaridade, clustering |
| **FastText** | 100-300 | Denso | ‚úÖ | Palavras fora vocabul√°rio |
| **Sentence Transformers** | 512-768 | Denso | ‚úÖ‚úÖ | Busca sem√¢ntica, Q&A |

### Modelos de ML

| Modelo | Accuracy | Treino | Predi√ß√£o | Interpret√°vel |
|--------|----------|--------|----------|---------------|
| **Naive Bayes** | 85% | ‚ö°‚ö°‚ö° | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê |
| **Logistic Reg** | 87% | ‚ö°‚ö° | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê |
| **LinearSVC** | 90% | ‚ö° | ‚ö°‚ö° | ‚≠ê‚≠ê |

---

## üíª Instala√ß√£o

### Requisitos
```
Python 3.7+
8GB RAM (m√≠nimo)
10GB espa√ßo em disco
```

### Setup Completo
```bash
# 1. Clonar reposit√≥rio
git clone https://github.com/usuario/EAI_04_NLP_Classico.git
cd EAI_04_NLP_Classico

# 2. Criar ambiente
conda create -n nlp_env python=3.9
conda activate nlp_env

# 3. Instalar depend√™ncias
pip install -r requirements.txt

# 4. Download recursos NLTK
python -c "import nltk; nltk.download('stopwords'); nltk.download('rslp')"
```

### Depend√™ncias Principais
```txt
# NLP Cl√°ssico
nltk>=3.8
gensim>=4.3
sentence-transformers>=2.2

# ML
scikit-learn>=1.3

# Dados
pandas>=2.0
numpy>=1.24

# Web
flask>=2.3

# Utilidades
beautifulsoup4>=4.12
matplotlib>=3.7
seaborn>=0.12
```

---

## üöÄ Execu√ß√£o R√°pida

### Notebooks
```bash
# Jupyter
jupyter notebook Fundamentos/

# Ou JupyterLab
jupyter lab
```

### Projetos

**An√°lise de Feedback**:
```bash
cd Projetos/Analise_de_Feedback
python app.py
# Acesse: http://localhost:5000
```

**Sistema de Busca FAQs**:
```bash
cd Projetos/Sistema_de_Busca_FAQs
python app.py
# Acesse: http://localhost:5000
```

---

## üéØ Checklist de Conclus√£o

### Fundamentos
- [ ] Executei os 6 notebooks
- [ ] Entendo BoW vs TF-IDF vs Embeddings
- [ ] Sei quando usar cada representa√ß√£o
- [ ] Domino pr√©-processamento de texto

### Modelos
- [ ] Treinei Naive Bayes
- [ ] Treinei SVM
- [ ] Comparei diferentes abordagens
- [ ] Sei escolher modelo por tarefa

### Projetos
- [ ] Executei An√°lise de Feedback
- [ ] Executei Sistema de Busca FAQs
- [ ] Testei com inputs pr√≥prios
- [ ] Adaptei para meus dados

### Avan√ßado
- [ ] Criei projeto pr√≥prio de NLP
- [ ] Fiz deploy em produ√ß√£o
- [ ] Integrei com sistema existente

---

## üìñ Recursos Complementares

### Cursos Online
- [Coursera: NLP Specialization](https://www.coursera.org/specializations/natural-language-processing)
- [Fast.ai: NLP](https://www.fast.ai/)
- [deeplearning.ai](https://www.deeplearning.ai/)

### Livros Recomendados
- "Speech and Language Processing" - Jurafsky & Martin
- "Natural Language Processing with Python" - Bird, Klein & Loper
- "Applied Text Analysis with Python" - Bengfort, Bilbro & Ojeda

### Bibliotecas
- [NLTK](https://www.nltk.org/) - Toolkit cl√°ssico
- [spaCy](https://spacy.io/) - NLP moderno
- [Gensim](https://radimrehurek.com/gensim/) - Word2Vec
- [Sentence Transformers](https://www.sbert.net/) - Embeddings

### Datasets em Portugu√™s
- [B2W-Reviews](https://github.com/americanas-tech/b2w-reviews01)
- [IMDB-PT](https://www.kaggle.com/datasets/luisfredgs/imdb-ptbr)
- [TweetSentBR](https://bitbucket.org/HBrum/tweetsentbr)

---

## üîÆ Pr√≥ximos Passos

Ap√≥s completar EAI_04, voc√™ estar√° pronto para:

### EAI_05 - NLP Moderno
- Transformers (arquitetura)
- BERT, RoBERTa, GPT
- Fine-tuning
- Hugging Face Transformers

### EAI_06 - NLP Avan√ßado
- Question Answering
- Named Entity Recognition
- Machine Translation
- Text Generation

### Projetos Avan√ßados
- Chatbots conversacionais
- RAG (Retrieval Augmented Generation)
- Sistemas multilingues
- An√°lise de sentimento multimodal

---

## ü§ù Contribuindo

Contribui√ß√µes s√£o bem-vindas!

**Como contribuir**:
1. Fork o reposit√≥rio
2. Crie branch (`git checkout -b feature/melhoria`)
3. Commit mudan√ßas
4. Push para branch
5. Abra Pull Request

**Ideias**:
- Novos notebooks de exemplos
- Datasets adicionais
- Melhorias na documenta√ß√£o
- Corre√ß√µes de bugs
- Tradu√ß√µes

---

## üìß Contato

**Autor**: Carlos Henrique Bamberg Marques  
**Email**: rick.bamberg@gmail.com  
**GitHub**: [@RickBamberg](https://github.com/RickBamberg/)  
**LinkedIn**: [carlos-henrique-bamberg-marques](https://www.linkedin.com/in/carlos-henrique-bamberg-marques/)

---

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja `LICENSE` para detalhes.

---

## üôè Agradecimentos

- Comunidade brasileira de NLP
- Autores de bibliotecas open-source (NLTK, spaCy, Gensim)
- Datasets p√∫blicos (B2W, BCB)
- Alunos e contribuidores

---

## üìä Estat√≠sticas do M√≥dulo

**Conte√∫do**:
- 6 notebooks fundamentais
- 3 notebooks de modelos
- 2 projetos deployados
- 12 arquivos de documenta√ß√£o
- ~5.000 linhas de c√≥digo
- ~120.000 palavras de documenta√ß√£o

**Tempo estimado**: 3-4 semanas (dedica√ß√£o parcial)

**N√≠vel**: Iniciante a Intermedi√°rio

---

**üí° Lembre-se**: NLP Cl√°ssico √© a base. Domine antes de partir para Transformers!

*Desenvolvido como parte do curso "Especialista em IA" - M√≥dulo EAI_04*
