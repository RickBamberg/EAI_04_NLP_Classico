{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63db3974-fc82-49c5-a237-c7ec13dbeb18",
   "metadata": {},
   "source": [
    "## Projeto Analise Feedback\n",
    "\n",
    "Este notebook tem como objetivo desenvolver dois modelos distintos de classifica√ß√£o de texto usando t√©cnicas cl√°ssicas de Processamento de Linguagem Natural (NLP):\n",
    "\n",
    "1. **Classifica√ß√£o de Sentimentos**: Dado um conjunto de avalia√ß√µes de produtos, o modelo identifica se cada avalia√ß√£o √© **positiva** ou **negativa**.\n",
    "2. **Classifica√ß√£o de Sugest√µes de Melhoria**: Dado um conjunto de frases variadas, o modelo identifica se o texto representa ou n√£o uma **sugest√£o de melhoria**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22e342e-decc-44eb-9cb5-9fc421b9fc85",
   "metadata": {},
   "source": [
    "### üì¶ Importa√ß√£o das Bibliotecas\n",
    "Importamos as bibliotecas necess√°rias para manipula√ß√£o de dados, treinamento de modelos e avalia√ß√£o de desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea780553-1af3-4181-a705-fa9e9a666148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b429cd-9ea0-455c-b1d5-ddbaab35000c",
   "metadata": {},
   "source": [
    "### üì• Carregamento dos Dados\n",
    "Aqui carregamos dois conjuntos de dados:\n",
    "\n",
    "- Sugest√µes de melhoria (sugestoes.txt)  \n",
    "      Fonte: Gerada por multiplas IA \n",
    "- Avalia√ß√µes de produtos (B2W-Reviews01.csv)  \n",
    "      Fonte: https://www.kaggle.com/datasets/fredericods/ptbr-sentiment-analysis-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "673c665b-3477-459c-b6c8-f46ea8188c85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando o carregamento dos dados ---\n",
      "‚úÖ Dataset de SUGEST√ïES carregado com 1506 exemplos.\n",
      "‚úÖ Dataset de OPINI√ïES (B2W) carregado com 129098 exemplos.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Iniciando o carregamento dos dados ---\")\n",
    "\n",
    "# --- 1.1 Carregando as SUGEST√ïES (melhorias.txt) ---\n",
    "arquivo_sugestoes = '../data/sugestoes.txt'\n",
    "try:\n",
    "    with open(arquivo_sugestoes, 'r', encoding='latin1') as f:\n",
    "        linhas = [linha.strip() for linha in f.readlines()]\n",
    "    df_sugestoes = pd.DataFrame(linhas, columns=['review_text'])\n",
    "    df_sugestoes['is_suggestion'] = 1\n",
    "    print(f\"‚úÖ Dataset de SUGEST√ïES carregado com {len(df_sugestoes)} exemplos.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO ao carregar o arquivo de sugest√µes: {e}\")\n",
    "\n",
    "# --- 1.2 Carregando as OPINI√ïES (B2W-Reviews01.csv) ---\n",
    "arquivo_opinioes = '../data/B2W-Reviews01.csv'\n",
    "try:\n",
    "    df_b2w = pd.read_csv(arquivo_opinioes, sep=',', dtype={'product_id': str})\n",
    "    df_b2w.dropna(subset=['review_text'], inplace=True)\n",
    "    print(f\"‚úÖ Dataset de OPINI√ïES (B2W) carregado com {len(df_b2w)} exemplos.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERRO ao carregar o arquivo B2W: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe9d0c3-a6cc-4cdd-9dac-a85a74ca7796",
   "metadata": {},
   "source": [
    "### üßπ Prepara√ß√£o dos Dados\n",
    "Preparamos os dados para dois objetivos diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb425b07-d365-4b9b-b0cd-34bcf5e47be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparando os dados para cada modelo de treinamento ---\n",
      "\n",
      "‚úÖ Dados para o Modelo de Sentimento prontos.\n",
      "sentiment\n",
      "1    79316\n",
      "0    33772\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ Dados para o Modelo de Sugest√£o prontos (dataset balanceado).\n",
      "is_suggestion\n",
      "1    1506\n",
      "0    1506\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Preparando os dados para cada modelo de treinamento ---\")\n",
    "\n",
    "# --- 2.1 Preparando os dados para o MODELO DE SENTIMENTO ---\n",
    "# Este modelo usa APENAS o dataset B2W para aprender o que √© positivo e negativo.\n",
    "\n",
    "# Cria um novo DataFrame a partir do B2W\n",
    "df_para_sentimento = df_b2w[['review_text', 'overall_rating']].copy()\n",
    "\n",
    "# Fun√ß√£o para mapear o sentimento\n",
    "def map_sentiment(rating):\n",
    "    if rating <= 2: return 0  # Negativo\n",
    "    elif rating >= 4: return 1  # Positivo\n",
    "    else: return None\n",
    "\n",
    "# Aplica o mapeamento e remove as avalia√ß√µes neutras\n",
    "df_para_sentimento['sentiment'] = df_para_sentimento['overall_rating'].apply(map_sentiment)\n",
    "df_para_sentimento.dropna(subset=['sentiment'], inplace=True)\n",
    "df_para_sentimento['sentiment'] = df_para_sentimento['sentiment'].astype(int)\n",
    "\n",
    "# Define X e y para este modelo\n",
    "X_sentimento = df_para_sentimento['review_text']\n",
    "y_sentimento = df_para_sentimento['sentiment']\n",
    "\n",
    "print(\"\\n‚úÖ Dados para o Modelo de Sentimento prontos.\")\n",
    "print(y_sentimento.value_counts())\n",
    "\n",
    "# --- 2.2 Preparando os dados para o MODELO DE SUGEST√ÉO ---\n",
    "# Este modelo usa as sugest√µes do seu arquivo .txt (classe 1) e\n",
    "# uma amostra de opini√µes \"puras\" do B2W (classe 0).\n",
    "\n",
    "# Define palavras-chave para FILTRAR o dataset B2W e pegar apenas opini√µes \"puras\"\n",
    "suggestion_keywords = [\n",
    "    'sugiro', 'sugest√£o', 'sugest√µes', 'poderia', 'poderiam', \n",
    "    'deveria', 'deviam', 'recomendo que', 'adicionar', \n",
    "    'melhorar', 'implementar', 'faltou', 'seria bom se'\n",
    "]\n",
    "keyword_pattern = '|'.join(suggestion_keywords)\n",
    "\n",
    "# Filtra o B2W, mantendo apenas as linhas que N√ÉO cont√™m as palavras-chave, e cria uma c√≥pia\n",
    "df_opinioes_limpas = df_b2w[~df_b2w['review_text'].str.contains(keyword_pattern, case=False, na=False)].copy()\n",
    "df_opinioes_limpas['is_suggestion'] = 0\n",
    "\n",
    "# Cria um dataset balanceado\n",
    "# Pega uma amostra das opini√µes limpas com o mesmo tamanho do seu dataset de sugest√µes\n",
    "df_opinioes_sample = df_opinioes_limpas.sample(n=len(df_sugestoes), random_state=42)\n",
    "\n",
    "# Combina as sugest√µes (classe 1) com a amostra de opini√µes (classe 0)\n",
    "df_para_sugestao = pd.concat([df_sugestoes, df_opinioes_sample[['review_text', 'is_suggestion']]], ignore_index=True)\n",
    "df_para_sugestao = df_para_sugestao.sample(frac=1, random_state=42).reset_index(drop=True) # Embaralha\n",
    "\n",
    "# Define X e y para este segundo modelo\n",
    "X_sugestao = df_para_sugestao['review_text']\n",
    "y_sugestao = df_para_sugestao['is_suggestion']\n",
    "\n",
    "print(\"\\n‚úÖ Dados para o Modelo de Sugest√£o prontos (dataset balanceado).\")\n",
    "print(y_sugestao.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7705016d-225b-4a01-b3af-03ba2e88f55b",
   "metadata": {},
   "source": [
    "### ü§ñ Treinamento do Modelo de Sentimento\n",
    "Utilizamos um Pipeline com TF-IDF + Regress√£o Log√≠stica para classificar os sentimentos nas avalia√ß√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbd11dfb-1cbd-4ded-83c8-c731a7e4257a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Treinando o Modelo de Sentimento ---\n",
      "Iniciando o treinamento do pipeline de sentimento...\n",
      "Treinamento conclu√≠do!\n",
      "\n",
      "Avaliando o modelo de sentimento...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.93      0.91      0.92      6755\n",
      "    Positivo       0.96      0.97      0.97     15863\n",
      "\n",
      "    accuracy                           0.95     22618\n",
      "   macro avg       0.94      0.94      0.94     22618\n",
      "weighted avg       0.95      0.95      0.95     22618\n",
      "\n",
      "‚úÖ Pipeline de Sentimento salvo em '../models\\sentiment_pipeline.pkl'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Treinando o Modelo de Sentimento ---\")\n",
    "\n",
    "# 1. Dividir os dados de SENTIMENTO em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_sentimento, y_sentimento, test_size=0.2, random_state=42, stratify=y_sentimento\n",
    ")\n",
    "\n",
    "# 2. Criar o pipeline para o modelo de sentimento\n",
    "pipeline_sentimento = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), max_features=50000)),\n",
    "    ('clf', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "# 3. Treinar o pipeline\n",
    "print(\"Iniciando o treinamento do pipeline de sentimento...\")\n",
    "pipeline_sentimento.fit(X_train, y_train)\n",
    "print(\"Treinamento conclu√≠do!\")\n",
    "\n",
    "# 4. Avaliar o modelo\n",
    "print(\"\\nAvaliando o modelo de sentimento...\")\n",
    "y_pred = pipeline_sentimento.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['Negativo', 'Positivo']))\n",
    "\n",
    "# 5. Salvar o pipeline treinado\n",
    "MODELS_DIR = '../models'\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.makedirs(MODELS_DIR)\n",
    "\n",
    "joblib.dump(pipeline_sentimento, os.path.join(MODELS_DIR, 'sentiment_pipeline.pkl'))\n",
    "print(f\"‚úÖ Pipeline de Sentimento salvo em '{os.path.join(MODELS_DIR, 'sentiment_pipeline.pkl')}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1371980-dda6-412c-891c-f460be15402a",
   "metadata": {},
   "source": [
    "### üß† Treinamento do Modelo de Sugest√£o\n",
    "Mesma arquitetura, mas focada em identificar sugest√µes expl√≠citas dentro de textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e74a026-a163-4364-9c19-0829b7fc97e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Treinando o Modelo de Sugest√£o ---\n",
      "Iniciando o treinamento do pipeline de sugest√£o...\n",
      "Treinamento conclu√≠do!\n",
      "\n",
      "Avaliando o modelo de sugest√£o...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "N√£o-Sugest√£o       0.97      0.99      0.98       302\n",
      "    Sugest√£o       0.99      0.97      0.98       301\n",
      "\n",
      "    accuracy                           0.98       603\n",
      "   macro avg       0.98      0.98      0.98       603\n",
      "weighted avg       0.98      0.98      0.98       603\n",
      "\n",
      "‚úÖ Pipeline de Sugest√£o salvo em '../models\\suggestion_pipeline.pkl'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n--- Treinando o Modelo de Sugest√£o ---\")\n",
    "\n",
    "# 1. Dividir os dados de SUGEST√ÉO em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_sugestao, y_sugestao, test_size=0.2, random_state=42, stratify=y_sugestao\n",
    ")\n",
    "\n",
    "# 2. Criar o pipeline para o modelo de sugest√£o\n",
    "# Podemos usar a mesma arquitetura de modelo\n",
    "pipeline_sugestao = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), max_features=50000)),\n",
    "    ('clf', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "# 3. Treinar o pipeline\n",
    "print(\"Iniciando o treinamento do pipeline de sugest√£o...\")\n",
    "pipeline_sugestao.fit(X_train, y_train)\n",
    "print(\"Treinamento conclu√≠do!\")\n",
    "\n",
    "# 4. Avaliar o modelo\n",
    "print(\"\\nAvaliando o modelo de sugest√£o...\")\n",
    "y_pred = pipeline_sugestao.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['N√£o-Sugest√£o', 'Sugest√£o']))\n",
    "\n",
    "# 5. Salvar o segundo pipeline treinado\n",
    "joblib.dump(pipeline_sugestao, os.path.join(MODELS_DIR, 'suggestion_pipeline.pkl'))\n",
    "print(f\"‚úÖ Pipeline de Sugest√£o salvo em '{os.path.join(MODELS_DIR, 'suggestion_pipeline.pkl')}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04abbd2-6874-4ac5-ad33-06aba9e2d07b",
   "metadata": {},
   "source": [
    "### ‚úÖ Conclus√£o\n",
    "Neste projeto, criamos dois modelos distintos:\n",
    "\n",
    "- Classifica√ß√£o de Sentimentos: Detecta se uma avalia√ß√£o √© positiva ou negativa com alta precis√£o.\n",
    "\n",
    "- Classifica√ß√£o de Sugest√µes: Identifica se um texto cont√©m uma sugest√£o ou n√£o, sendo √∫til para extra√ß√£o de feedbacks construtivos.\n",
    "\n",
    "Ambos os modelos demonstraram alto desempenho nos testes, com acur√°cia acima de 95%, o que os torna prontos para aplica√ß√µes reais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1db7bbe-4e6d-4320-9c7c-e70bf077abe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (faq_env)",
   "language": "python",
   "name": "faq_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
