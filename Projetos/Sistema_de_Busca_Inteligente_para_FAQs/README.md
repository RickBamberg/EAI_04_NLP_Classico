# ğŸ” Sistema de Busca Inteligente para FAQs

Sistema de busca semÃ¢ntica para base de conhecimento com **Sentence Transformers**, capaz de entender o significado da pergunta (nÃ£o apenas palavras-chave) usando embeddings e similaridade de cosseno.

---

## ğŸ¯ Objetivo

Criar um sistema de autoatendimento inteligente que:
1. **Entende contexto**: NÃ£o busca palavras exatas, busca significado
2. **Ranqueia respostas**: Top 3 mais relevantes com score
3. **Filtra irrelevÃ¢ncias**: Threshold mÃ­nimo de 50% de similaridade

**Resultado**: ReduÃ§Ã£o de carga em suporte, respostas instantÃ¢neas 24/7.

---

## ğŸ§  Como Funciona

### Busca Tradicional vs Busca SemÃ¢ntica

**Busca Tradicional** (Keyword-based):
```
UsuÃ¡rio: "Como fazer PIX?"
Sistema: Busca por "fazer" AND "PIX"
Resultado: Pode nÃ£o encontrar se FAQ usa "realizar" em vez de "fazer"
```

**Busca SemÃ¢ntica** (Este projeto):
```
UsuÃ¡rio: "Como fazer PIX?"
Sistema: Entende significado â†’ Compara com todos FAQs
Resultado: Encontra "Como realizar transferÃªncia PIX" (similaridade 87%)
```

### Pipeline Visual

```
Pergunta do UsuÃ¡rio
    â†“
Sentence Transformer (embedding 512D)
    â†“
Comparar com Base (1.172 embeddings)
    â†“
Similaridade de Cosseno
    â†“
Top 3 Resultados (â‰¥50% similaridade)
    â†“
Exibir com Score
```

---

## ğŸ—ï¸ Arquitetura do Sistema

### Modelo: Sentence Transformers

**Modelo usado**: `distiluse-base-multilingual-cased-v1`

**Por quÃª?**
- âœ… MultilÃ­ngue (funciona bem em portuguÃªs)
- âœ… Embeddings de 512 dimensÃµes (menor que BERT 768D)
- âœ… Distilado (mais rÃ¡pido, leve)
- âœ… Captura semÃ¢ntica de sentenÃ§as completas

**Arquitetura**:
```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('distiluse-base-multilingual-cased-v1')

# Converter texto em vetor
embedding = model.encode("Como fazer PIX?")
# Output: array de 512 nÃºmeros (vetor semÃ¢ntico)
```

### Similaridade de Cosseno

**FÃ³rmula**:
```
cos(Î¸) = (A Â· B) / (||A|| Ã— ||B||)

Onde:
- A = embedding da pergunta do usuÃ¡rio
- B = embedding de cada FAQ
- Resultado: -1 a 1 (convertido para 0% a 100%)
```

**Por que cosseno?**
- âœ… DireÃ§Ã£o importa mais que magnitude
- âœ… Normalizado (sempre entre -1 e 1)
- âœ… RÃ¡pido de computar

---

## ğŸ“Š Dataset - FAQs do Banco Central

### Fonte

**URL**: https://www.bcb.gov.br/api/servico/faq/faqperguntas

**CaracterÃ­sticas**:
- 1.172 pares de pergunta/resposta
- Temas: PIX, emprÃ©stimos, Registrato, etc.
- Formato original: JSON com HTML nas respostas

### Estrutura Original (JSON)

```json
{
  "conteudo": [
    {
      "pergunta": "O que Ã© Registrato?",
      "resposta": "<p>O Registrato Ã© um sistema onde vocÃª pode...</p>"
    },
    ...
  ]
}
```

### Limpeza de Dados

**Problema**: Respostas contÃªm HTML

```html
<p>O Registrato Ã© um sistema onde vocÃª pode consultar...</p>
<ul><li>Item 1</li><li>Item 2</li></ul>
```

**SoluÃ§Ã£o**: BeautifulSoup para extrair texto puro

```python
from bs4 import BeautifulSoup

def limpar_html(texto_html):
    if not isinstance(texto_html, str):
        return ""
    soup = BeautifulSoup(texto_html, "html.parser")
    return soup.get_text(separator=' ', strip=True)

df['resposta_limpa'] = df['resposta'].apply(limpar_html)
```

**Resultado**:
```
"O Registrato Ã© um sistema onde vocÃª pode consultar... Item 1 Item 2"
```

### DataFrame Final

```python
df_faq_limpo.head()

         pergunta                                          resposta
0  O que Ã© Registrato?  O Registrato Ã© um sistema onde vocÃª pode...
1  Como acesso o PIX?   Para acessar o PIX, vocÃª precisa...
...
```

**Total**: 1.172 pares pergunta/resposta limpos

---

## ğŸš€ Como Usar

### 1. InstalaÃ§Ã£o

```bash
# Clonar repositÃ³rio
git clone https://github.com/RickBamberg/Sistema_de_Busca_FAQs.git
cd Sistema_de_Busca_FAQs

# Criar ambiente virtual (Conda)
conda create --name faq_env python=3.9
conda activate faq_env

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 2. Gerar Embeddings (Primeira vez)

```bash
# Executar notebook
jupyter notebook notebook/FAQ_Semantic_Search.ipynb

# Ou via Python
python scripts/generate_embeddings.py
```

**O que Ã© gerado**:
- `models/embeddings_faq.npy` (matriz 1172Ã—512)
- `models/dados_faq.pkl` (perguntas e respostas)

### 3. Executar AplicaÃ§Ã£o Flask

```bash
python app.py
```

**Acesse**: http://localhost:5000

### 4. Usar Interface

1. Digite uma pergunta (ex: "Como fazer PIX?")
2. Clique em **"Buscar"**
3. Veja Top 3 resultados com score de similaridade

---

## ğŸ“ Estrutura do Projeto

```
Sistema_de_Busca_FAQs/
â”œâ”€â”€ app.py                      # ğŸŒ Backend Flask
â”œâ”€â”€ requirements.txt            # ğŸ“¦ DependÃªncias
â”œâ”€â”€ README.md                   # ğŸ“„ Este arquivo
â”œâ”€â”€ AGENT_CONTEXT.md           # ğŸ¤– DocumentaÃ§Ã£o tÃ©cnica
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ FAQ_BB.json            # Dataset original (BCB)
â”‚
â”œâ”€â”€ models/                     # ğŸ’¾ Artefatos gerados
â”‚   â”œâ”€â”€ embeddings_faq.npy     # Matriz de embeddings (1172Ã—512)
â”‚   â””â”€â”€ dados_faq.pkl          # Perguntas e respostas
â”‚
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ FAQ_Semantic_Search.ipynb  # ğŸ““ GeraÃ§Ã£o de embeddings
â”‚
â”œâ”€â”€ static/
â”‚   â””â”€â”€ css/
â”‚       â””â”€â”€ style.css          # ğŸ¨ Estilos
â”‚
â””â”€â”€ templates/                  # ğŸ–¼ï¸ Interface web
    â”œâ”€â”€ index.html
    â””â”€â”€ resultado.html
```

---

## ğŸŒ AplicaÃ§Ã£o Flask

### Backend (app.py)

```python
from flask import Flask, render_template, request
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import pickle
import numpy as np

app = Flask(__name__)

# Carregar artefatos (uma vez)
with open('models/dados_faq.pkl', 'rb') as f:
    dados_faq = pickle.load(f)
embeddings_perguntas = np.load('models/embeddings_faq.npy')
model = SentenceTransformer('distiluse-base-multilingual-cased-v1')

def buscar_resposta_similar(pergunta_usuario, top_k=3, threshold=0.5):
    """
    Busca Top K respostas com similaridade >= threshold
    """
    # 1. Gerar embedding da pergunta
    embedding_usuario = model.encode([pergunta_usuario])
    
    # 2. Calcular similaridade com todos FAQs
    similaridades = cosine_similarity(
        embedding_usuario,
        embeddings_perguntas
    )[0]
    
    # 3. Pegar Top K
    indices_top = np.argsort(similaridades)[::-1][:top_k]
    
    # 4. Filtrar por threshold
    resultados = []
    for idx in indices_top:
        score = similaridades[idx]
        if score >= threshold:
            resultados.append({
                'pergunta': dados_faq['perguntas'][idx],
                'resposta': dados_faq['respostas'][idx],
                'similaridade': f"{score:.2%}"
            })
    
    return resultados

@app.route('/')
def home():
    return render_template('index.html')

@app.route('/predict', methods=['POST'])
def predict():
    pergunta = request.form.get('message', '').strip()
    
    resultados = buscar_resposta_similar(
        pergunta,
        top_k=3,
        threshold=0.5
    )
    
    return render_template('resultado.html',
                         pergunta_usuario=pergunta,
                         resultados=resultados,
                         total_resultados=len(resultados))
```

### Frontend

**index.html**: FormulÃ¡rio de busca  
**resultado.html**: Top 3 resultados com score

---

## ğŸ“š Tecnologias Utilizadas

| Categoria | Tecnologia | Uso |
|-----------|-----------|-----|
| **NLP** | Sentence Transformers | Embeddings semÃ¢nticos |
| **ML** | scikit-learn | Similaridade de cosseno |
| **Dados** | Pandas, NumPy | ManipulaÃ§Ã£o de dados |
| **Limpeza** | BeautifulSoup4 | Remover HTML |
| **Web** | Flask | Backend |
| **Frontend** | HTML/CSS | Interface |
| **PersistÃªncia** | pickle, NumPy | Salvar embeddings |

---

## ğŸ“Š Exemplos de Uso

### Exemplo 1: Busca Direta

**Input**:
```
"Como fazer transferÃªncia PIX?"
```

**Output**:
```
Top 3 Resultados:

1. Como acesso o PIX?
   Similaridade: 87%
   Resposta: Para acessar o PIX, vocÃª precisa...

2. Como faÃ§o para cadastrar chave PIX?
   Similaridade: 74%
   Resposta: O cadastro de chave PIX pode ser feito...

3. Qual o limite de transferÃªncia PIX?
   Similaridade: 62%
   Resposta: O limite de transferÃªncia depende...
```

---

### Exemplo 2: SinÃ´nimos

**Input**:
```
"Como realizar pagamento instantÃ¢neo?"
```

**Output**:
```
Top 3 Resultados:

1. Como acesso o PIX?
   Similaridade: 81%
   (PIX Ã© pagamento instantÃ¢neo - modelo entende!)
```

---

### Exemplo 3: Pergunta Fora do Escopo

**Input**:
```
"Qual a previsÃ£o do tempo amanhÃ£?"
```

**Output**:
```
Nenhum resultado encontrado com confianÃ§a suficiente.
(Todos abaixo de 50% threshold)
```

---

### Exemplo 4: VariaÃ§Ã£o de FormulaÃ§Ã£o

**Input 1**: "Como cadastrar chave PIX?"  
**Input 2**: "Qual o processo para registrar chave no PIX?"

**Ambos retornam**:
```
Como faÃ§o para cadastrar chave PIX?
Similaridade: ~85%
```

**Por quÃª?** Embeddings capturam significado, nÃ£o palavras exatas.

---

## ğŸ” Como o Sistema Decide?

### Embeddings Capturam SemÃ¢ntica

```python
# Exemplo simplificado (512D â†’ 3D para visualizaÃ§Ã£o)

"Como fazer PIX?" â†’ [0.8, 0.3, 0.1]
"Como realizar PIX?" â†’ [0.79, 0.31, 0.09]  # Muito similar!
"Qual o horÃ¡rio do banco?" â†’ [0.1, 0.7, 0.6]  # Diferente

# Similaridade de cosseno
cos("Como fazer PIX?", "Como realizar PIX?") = 0.98 (98%)
cos("Como fazer PIX?", "Qual horÃ¡rio banco?") = 0.23 (23%)
```

### Threshold de 50%

**Por que 50%?**
- âœ… Evita respostas sem sentido
- âœ… Balanceia recall vs precision
- âš ï¸ AjustÃ¡vel conforme necessidade

**Experimentos**:
```
Threshold 30%: Muitos falsos positivos
Threshold 50%: Balanceado âœ“
Threshold 70%: Perde resultados vÃ¡lidos
```

---

## ğŸ“ˆ Performance e LimitaÃ§Ãµes

### Quando Funciona Bem

- âœ… Perguntas dentro do domÃ­nio (PIX, emprÃ©stimos, Registrato)
- âœ… VariaÃ§Ãµes de formulaÃ§Ã£o da mesma pergunta
- âœ… SinÃ´nimos ("fazer" vs "realizar")
- âœ… Perguntas completas (>5 palavras)

### Quando Pode Falhar

- âŒ Perguntas muito genÃ©ricas ("Como funciona?")
- âŒ TÃ³picos fora da base de conhecimento
- âŒ Perguntas muito curtas (<3 palavras)
- âŒ GÃ­rias ou termos tÃ©cnicos nÃ£o presentes no FAQ

### MÃ©tricas TÃ­picas

```
Top-1 Accuracy: ~75%
Top-3 Accuracy: ~90%
Velocidade: <1s por busca
```

---

## ğŸ”® Melhorias Futuras

### Dados
- [ ] Expandir base de conhecimento (3k+ FAQs)
- [ ] Adicionar FAQs de mÃºltiplos bancos
- [ ] Feedback do usuÃ¡rio ("resposta Ãºtil?")
- [ ] Re-treinar modelo com feedback

### Modelo
- [ ] Testar modelos maiores (BERT base portuguÃªs)
- [ ] Fine-tuning em domÃ­nio financeiro
- [ ] Usar reranker (bi-encoder + cross-encoder)
- [ ] Adicionar filtros (categoria, data)

### AplicaÃ§Ã£o
- [ ] API REST para integraÃ§Ã£o
- [ ] HistÃ³rico de buscas
- [ ] Analytics (perguntas mais frequentes)
- [ ] Chatbot conversacional (multi-turn)
- [ ] Deploy em cloud (Heroku, Railway)

### UX
- [ ] SugestÃµes de perguntas populares
- [ ] Autocomplete
- [ ] "VocÃª quis dizer...?"
- [ ] Exportar FAQ em PDF

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas!

**Como contribuir**:
1. Fork o repositÃ³rio
2. Crie uma branch (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

**Ideias de contribuiÃ§Ã£o**:
- Adicionar mais FAQs
- Melhorar UI/UX
- Implementar API REST
- Adicionar testes automatizados
- Criar dashboard de analytics

---

## ğŸ“– Recursos Adicionais

### Sentence Transformers
- [DocumentaÃ§Ã£o](https://www.sbert.net/)
- [Modelos disponÃ­veis](https://www.sbert.net/docs/pretrained_models.html)
- [Paper original](https://arxiv.org/abs/1908.10084)

### Similaridade SemÃ¢ntica
- [Cosine Similarity Explained](https://en.wikipedia.org/wiki/Cosine_similarity)
- [Semantic Search Tutorial](https://www.sbert.net/examples/applications/semantic-search/README.html)

### Datasets Similares
- [Stack Overflow Questions](https://www.kaggle.com/datasets/stackoverflow/stacksample)
- [Quora Question Pairs](https://www.kaggle.com/c/quora-question-pairs)

---

## ğŸ“ CitaÃ§Ã£o

Se usar este projeto, por favor cite:

```
@misc{sistema_busca_faq_2026,
  author = {Carlos Henrique Bamberg Marques},
  title = {Sistema de Busca Inteligente para FAQs com Sentence Transformers},
  year = {2026},
  publisher = {GitHub},
  url = {https://github.com/RickBamberg/Sistema_de_Busca_FAQs}
}
```

---

## ğŸ“§ Contato

**Autor**: Carlos Henrique Bamberg Marques  
**Email**: rick.bamberg@gmail.com  
**GitHub**: [@RickBamberg](https://github.com/RickBamberg/)  
**LinkedIn**: [carlos-henrique-bamberg-marques](https://www.linkedin.com/in/carlos-henrique-bamberg-marques/)

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

---

## ğŸ™ Agradecimentos

- [Banco Central do Brasil](https://www.bcb.gov.br/) - Dataset de FAQs
- [Sentence Transformers](https://www.sbert.net/) - Biblioteca de embeddings
- [Flask](https://flask.palletsprojects.com/) - Framework web
- Comunidade de NLP brasileira

---

**ğŸ’¡ Dica**: Busca semÃ¢ntica Ã© o futuro! Este Ã© um Ã³timo baseline para chatbots e sistemas de Q&A.

*Projeto desenvolvido como parte do curso "Especialista em IA" - MÃ³dulo EAI_04*
