# AGENT_CONTEXT.md - Sistema de Busca Inteligente para FAQs

> **Prop√≥sito**: Contexto t√©cnico completo do sistema de busca sem√¢ntica  
> **√öltima atualiza√ß√£o**: Janeiro 2026  
> **Tipo**: Projeto real com Sentence Transformers e deployment Flask

## RESUMO EXECUTIVO

**Objetivo**: Busca sem√¢ntica em base de conhecimento FAQ usando embeddings  
**Modelo**: distiluse-base-multilingual-cased-v1 (Sentence Transformers)  
**Dataset**: 1.172 FAQs do Banco Central do Brasil  
**M√©todo**: Similaridade de cosseno entre embeddings  
**Performance**: Top-3 Accuracy ~90%, <1s por busca  
**Deployment**: Flask web app  
**Diferencial**: Entende significado, n√£o apenas palavras-chave

---

## PROBLEMA - BUSCA SEM√ÇNTICA

### Limita√ß√µes da Busca por Palavras-chave

**Busca Tradicional (TF-IDF, BM25)**:
```python
# Problema 1: Sin√¥nimos n√£o s√£o reconhecidos
Query: "Como fazer PIX?"
FAQ:   "Como realizar transfer√™ncia PIX?"
Match: Baixo (s√≥ "PIX" em comum)

# Problema 2: Ordem das palavras importa
Query: "PIX fazer como?"
FAQ:   "Como fazer PIX?"
Match: Baixo (ordem diferente)
```

**Busca Sem√¢ntica (Embeddings)**:
```python
# Solu√ß√£o: Vetores capturam significado
Query: "Como fazer PIX?" ‚Üí embedding_query
FAQ:   "Como realizar transfer√™ncia PIX?" ‚Üí embedding_faq

Similaridade(embedding_query, embedding_faq) = 0.87 (87%)
# Alto! Mesmo sem palavras exatas iguais
```

### Por Que Sentence Transformers?

**Alternativas descartadas**:
```python
# 1. TF-IDF
- N√£o captura sem√¢ntica
- Baseado em frequ√™ncia de palavras
- Sin√¥nimos = palavras diferentes

# 2. Word2Vec/FastText
- Embeddings de palavras, n√£o senten√ßas
- Precisa agrega√ß√£o (m√©dia) ‚Üí perde contexto

# 3. BERT full
- 768 dimens√µes (vs 512 SentenceTransformers)
- Mais lento
- Mais pesado para deployment
```

**Sentence Transformers** ‚úÖ:
- Embeddings de senten√ßas completas
- Treinado para similaridade sem√¢ntica
- Multil√≠ngue (funciona em portugu√™s)
- Leve e r√°pido

---

## DATASET - FAQS DO BANCO CENTRAL

### Fonte Original

**API do BCB**:
```python
URL = "https://www.bcb.gov.br/api/servico/faq/faqperguntas"

# Retorna JSON
{
  "conteudo": [
    {
      "id": "1",
      "pergunta": "O que √© Registrato?",
      "resposta": "<p>O Registrato √© um sistema...</p>",
      "categoria": "Registrato",
      "subcategoria": "Geral"
    },
    ...
  ]
}
```

**Total**: 1.172 pares pergunta/resposta

### Limpeza de Dados

#### Problema: HTML nas Respostas

**Resposta Original**:
```html
<p>O Registrato √© um sistema onde voc√™ pode consultar:</p>
<ul>
  <li>Relat√≥rio de Chaves Pix</li>
  <li>Relat√≥rio de Empr√©stimos</li>
</ul>
<p>Para acessar, clique <a href="...">aqui</a>.</p>
```

**Problema**:
- Tags HTML n√£o s√£o √∫teis para usu√°rio
- Dificulta leitura
- Adiciona ru√≠do nos embeddings

#### Solu√ß√£o: BeautifulSoup

```python
from bs4 import BeautifulSoup

def limpar_html(texto_html):
    """
    Remove todas as tags HTML e retorna texto puro
    """
    if not isinstance(texto_html, str):
        return ""
    
    # Parser HTML
    soup = BeautifulSoup(texto_html, "html.parser")
    
    # Extrair texto
    texto_limpo = soup.get_text(
        separator=' ',  # Espa√ßo entre elementos
        strip=True      # Remove espa√ßos extras
    )
    
    return texto_limpo

# Aplicar
df['resposta_limpa'] = df['resposta'].apply(limpar_html)
```

**Resposta Limpa**:
```
O Registrato √© um sistema onde voc√™ pode consultar: Relat√≥rio de Chaves Pix Relat√≥rio de Empr√©stimos Para acessar, clique aqui.
```

### Pipeline Completo de Limpeza

```python
import pandas as pd
import json

# 1. Carregar JSON
with open('FAQ_BB.json', 'r', encoding='utf-8') as f:
    dados_json = json.load(f)

df = pd.DataFrame(dados_json['conteudo'])

# 2. Limpar HTML
df['resposta_limpa'] = df['resposta'].apply(limpar_html)

# 3. Remover vazios/nulos
df_faq_limpo = df[['pergunta', 'resposta_limpa']].copy()
df_faq_limpo.dropna(inplace=True)
df_faq_limpo = df_faq_limpo[df_faq_limpo['pergunta'] != '']

# 4. Renomear
df_faq_limpo.rename(columns={'resposta_limpa': 'resposta'}, inplace=True)

# Resultado: 1.172 pares limpos
```

---

## MODELO - SENTENCE TRANSFORMERS

### Arquitetura: distiluse-base-multilingual-cased-v1

**Caracter√≠sticas**:
- **Base**: DistilBERT (destilado do BERT)
- **Multil√≠ngue**: Treinado em 50+ idiomas
- **Dimens√µes**: 512 (vs 768 BERT original)
- **Tokenizer**: WordPiece (32k vocab)
- **Pooling**: Mean pooling (m√©dia dos tokens)

**Treinamento**:
```
Dataset: Billions de pares de senten√ßas
Tarefa: Similaridade sem√¢ntica (STS)
M√©todo: Contrastive learning
```

### Gera√ß√£o de Embeddings

```python
from sentence_transformers import SentenceTransformer

# Carregar modelo
model = SentenceTransformer('distiluse-base-multilingual-cased-v1')

# Gerar embeddings para todas as perguntas
perguntas = df_faq_limpo['pergunta'].tolist()
# ['O que √© Registrato?', 'Como acesso o PIX?', ...]

embeddings_perguntas = model.encode(
    perguntas,
    show_progress_bar=True,
    batch_size=32,
    normalize_embeddings=False  # Normalizar depois, se necess√°rio
)

# Output
print(embeddings_perguntas.shape)
# (1172, 512)
```

**Explica√ß√£o**:
```python
# Para cada pergunta:
"O que √© Registrato?" 
    ‚Üì Tokenization
["o", "que", "√©", "registrato", "?"]
    ‚Üì BERT Encoding
[[0.23, -0.45, ...], [0.67, 0.12, ...], ...]  # 5 tokens √ó 512 dim
    ‚Üì Mean Pooling
[0.34, -0.21, 0.56, ...]  # 1 √ó 512 dim
    ‚Üì Output
embedding de 512 dimens√µes
```

### Salvar Artefatos

```python
import numpy as np
import pickle
import os

# Criar diret√≥rio
MODELS_DIR = 'models'
os.makedirs(MODELS_DIR, exist_ok=True)

# 1. Salvar embeddings (matriz NumPy)
np.save(
    os.path.join(MODELS_DIR, 'embeddings_faq.npy'),
    embeddings_perguntas
)

# 2. Salvar perguntas e respostas (pickle)
with open(os.path.join(MODELS_DIR, 'dados_faq.pkl'), 'wb') as f:
    pickle.dump({
        'perguntas': df_faq_limpo['pergunta'].tolist(),
        'respostas': df_faq_limpo['resposta'].tolist()
    }, f)
```

**Tamanhos**:
```
embeddings_faq.npy: ~2.4 MB (1172 √ó 512 √ó 4 bytes float32)
dados_faq.pkl:      ~500 KB (textos comprimidos)
Total:              ~3 MB
```

---

## BUSCA SEM√ÇNTICA - SIMILARIDADE DE COSSENO

### Por Que Similaridade de Cosseno?

**Alternativas**:
```python
# 1. Dist√¢ncia Euclidiana
dist = np.linalg.norm(A - B)
# Problema: Magnitude importa
# Vetores grandes = dist√¢ncia grande (mesmo se mesma dire√ß√£o)

# 2. Produto Escalar (Dot Product)
dot = np.dot(A, B)
# Problema: Sem normaliza√ß√£o
# Vetores grandes = produto grande

# 3. Similaridade de Cosseno ‚úì
cos_sim = np.dot(A, B) / (np.linalg.norm(A) * np.linalg.norm(B))
# Vantagem: Apenas dire√ß√£o importa (0 a 1)
```

### F√≥rmula Matem√°tica

```
                    A ¬∑ B
cos(Œ∏) = ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
          ||A|| √ó ||B||

Onde:
- A ¬∑ B = produto escalar
- ||A|| = norma (magnitude) de A
- ||B|| = norma de B

Resultado: -1 a 1
- 1  = vetores id√™nticos (Œ∏ = 0¬∞)
- 0  = ortogonais (Œ∏ = 90¬∞)
- -1 = opostos (Œ∏ = 180¬∞)
```

### Implementa√ß√£o

```python
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

def buscar_resposta_similar(pergunta_usuario, top_k=3, threshold=0.5):
    """
    Busca as top_k respostas mais similares acima do threshold
    
    Args:
        pergunta_usuario (str): Pergunta do usu√°rio
        top_k (int): N√∫mero de resultados a retornar
        threshold (float): Similaridade m√≠nima (0-1)
    
    Returns:
        list: Lista de dicion√°rios com resultados
    """
    # 1. Gerar embedding da pergunta do usu√°rio
    embedding_usuario = model.encode([pergunta_usuario])
    # Shape: (1, 512)
    
    # 2. Calcular similaridade com TODOS os FAQs
    similaridades = cosine_similarity(
        embedding_usuario,           # (1, 512)
        embeddings_perguntas         # (1172, 512)
    )[0]  # Pega primeira linha ‚Üí shape (1172,)
    
    # 3. Ordenar por similaridade (maior ‚Üí menor)
    indices_ordenados = np.argsort(similaridades)[::-1]
    # [::-1] inverte para descendente
    
    # 4. Pegar top_k
    indices_top = indices_ordenados[:top_k]
    
    # 5. Filtrar por threshold
    resultados = []
    for i, idx in enumerate(indices_top):
        score = similaridades[idx]
        
        if score >= threshold:
            resultados.append({
                'posicao': len(resultados) + 1,
                'pergunta': dados_faq['perguntas'][idx],
                'resposta': dados_faq['respostas'][idx],
                'similaridade': f"{score:.2%}",
                'score_raw': score
            })
    
    return resultados
```

### Exemplo Detalhado

```python
# Pergunta do usu√°rio
query = "Como fazer transfer√™ncia PIX?"

# 1. Embedding
embedding_query = model.encode([query])
# [[0.23, -0.45, 0.67, ..., 0.12]]  # (1, 512)

# 2. Similaridades com todos FAQs
sims = cosine_similarity(embedding_query, embeddings_perguntas)[0]
# [0.87, 0.32, 0.74, 0.23, ..., 0.15]  # (1172,)

# 3. Top 3 √≠ndices
top3_idx = np.argsort(sims)[::-1][:3]
# [42, 156, 789]

# 4. Resultados
for idx in top3_idx:
    print(f"Pergunta: {perguntas[idx]}")
    print(f"Similaridade: {sims[idx]:.2%}")
    print()

# Output:
# Pergunta: Como acesso o PIX?
# Similaridade: 87%
# 
# Pergunta: Como fa√ßo para cadastrar chave PIX?
# Similaridade: 74%
# 
# Pergunta: Qual o limite de transfer√™ncia PIX?
# Similaridade: 62%
```

---

## THRESHOLD DE CONFIAN√áA

### Por Que Threshold = 0.5 (50%)?

**Experimentos**:
```python
# Threshold muito baixo (30%)
- Vantagem: Retorna mais resultados
- Problema: Muitos falsos positivos

Exemplo:
Query: "Como fazer PIX?"
Resultado com 32%: "O que √© Registrato?"
‚Üí Irrelevante!

# Threshold balanceado (50%) ‚úì
- Vantagem: Filtra irrelev√¢ncias
- Trade-off: Pode perder resultados marginais

# Threshold muito alto (70%)
- Vantagem: Alta precision
- Problema: Baixo recall (perde resultados v√°lidos)

Exemplo:
Query: "Como realizar transfer√™ncia PIX?"
Resultado ignorado com 68%: "Como fazer PIX?"
‚Üí Perdeu resultado bom!
```

**Configura√ß√£o**:
```python
def buscar_resposta_similar(pergunta_usuario, top_k=3, threshold=0.5):
    # threshold ajust√°vel
    # Produ√ß√£o: Pode variar por caso de uso
```

**Recomenda√ß√µes por Dom√≠nio**:
```python
# FAQ T√©cnico (precis√£o importante)
threshold = 0.6  # S√≥ respostas muito relevantes

# FAQ Geral (recall importante)
threshold = 0.4  # Mais resultados

# FAQ Banc√°rio (este projeto)
threshold = 0.5  # Balanceado
```

---

## DEPLOYMENT FLASK

### app.py - Backend Completo

```python
from flask import Flask, render_template, request
import pickle
import numpy as np
import os
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

# ===== INICIALIZA√á√ÉO =====
app = Flask(__name__)
app.config['TEMPLATES_AUTO_RELOAD'] = True
app.secret_key = 'chave_secreta_qualquer'

# ===== CARREGAR ARTEFATOS (UMA VEZ) =====
MODELS_DIR = 'models'
DADOS_PATH = os.path.join(MODELS_DIR, 'dados_faq.pkl')
EMBEDDINGS_PATH = os.path.join(MODELS_DIR, 'embeddings_faq.npy')

try:
    # Dados
    with open(DADOS_PATH, 'rb') as f:
        dados_faq = pickle.load(f)
    
    # Embeddings
    embeddings_perguntas = np.load(EMBEDDINGS_PATH)
    
    # Modelo (download autom√°tico na primeira vez)
    model = SentenceTransformer('distiluse-base-multilingual-cased-v1')
    
    print("‚úÖ Sistema carregado com sucesso!")
    print(f"   FAQs: {len(dados_faq['perguntas'])}")
    print(f"   Embeddings: {embeddings_perguntas.shape}")
    
except Exception as e:
    print(f"‚ùå Erro ao carregar: {e}")
    dados_faq = None
    embeddings_perguntas = None
    model = None

# ===== FUN√á√ÉO DE BUSCA =====
def buscar_resposta_similar(pergunta_usuario, top_k=3, threshold=0.5):
    """
    Busca sem√¢ntica com threshold
    """
    if not dados_faq or embeddings_perguntas is None or not model:
        return []
    
    try:
        # 1. Embedding da pergunta
        embedding_usuario = model.encode([pergunta_usuario])
        
        # 2. Similaridades
        similaridades = cosine_similarity(
            embedding_usuario,
            embeddings_perguntas
        )[0]
        
        # 3. Top K √≠ndices
        indices_top = np.argsort(similaridades)[::-1][:top_k]
        
        # 4. Filtrar por threshold
        resultados = []
        for idx in indices_top:
            score = similaridades[idx]
            
            if score >= threshold:
                resultados.append({
                    'posicao': len(resultados) + 1,
                    'pergunta': dados_faq['perguntas'][idx],
                    'resposta': dados_faq['respostas'][idx],
                    'similaridade': f"{score:.2%}"
                })
        
        return resultados
        
    except Exception as e:
        print(f"Erro na busca: {e}")
        return []

# ===== ROTAS =====
@app.route('/')
def home():
    """P√°gina inicial com formul√°rio"""
    return render_template('index.html')

@app.route('/predict', methods=['POST'])
def predict():
    """Processa busca e retorna resultados"""
    # Verificar sistema
    if not dados_faq or embeddings_perguntas is None or not model:
        return "Erro: Sistema de FAQ n√£o dispon√≠vel.", 500
    
    # Receber pergunta
    pergunta = request.form.get('message', '').strip()
    
    if not pergunta:
        return render_template('index.html',
                             error="Por favor, digite sua d√∫vida.")
    
    try:
        # Buscar
        resultados = buscar_resposta_similar(
            pergunta,
            top_k=3,
            threshold=0.5
        )
        
        # Renderizar resultado
        return render_template('resultado.html',
                             pergunta_usuario=pergunta,
                             resultados=resultados,
                             total_resultados=len(resultados))
    
    except Exception as e:
        print(f"Erro durante busca: {e}")
        return render_template('index.html',
                             error="Erro interno. Tente novamente.")

# ===== EXECUTAR =====
if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
```

### templates/resultado.html

```html
<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <title>Resultados - Busca FAQ</title>
    <link rel="stylesheet" href="{{ url_for('static', filename='css/style.css') }}">
</head>
<body>
    <div class="container">
        <h1>üîç Resultados da Busca</h1>
        
        <div class="pergunta-usuario">
            <h3>Sua pergunta:</h3>
            <p>{{ pergunta_usuario }}</p>
        </div>
        
        {% if total_resultados > 0 %}
        <p class="info">Encontramos {{ total_resultados }} resultado(s) relevante(s):</p>
        
        {% for resultado in resultados %}
        <div class="resultado-card">
            <div class="resultado-header">
                <span class="posicao">#{{ resultado.posicao }}</span>
                <span class="similaridade">{{ resultado.similaridade }}</span>
            </div>
            <h4>{{ resultado.pergunta }}</h4>
            <p class="resposta">{{ resultado.resposta }}</p>
        </div>
        {% endfor %}
        
        {% else %}
        <div class="sem-resultados">
            <p>üòï Nenhum resultado encontrado com confian√ßa suficiente.</p>
            <p>Tente reformular sua pergunta ou entre em contato com o suporte.</p>
        </div>
        {% endif %}
        
        <a href="/" class="voltar">‚Üê Nova busca</a>
    </div>
</body>
</html>
```

---

## PERFORMANCE E OTIMIZA√á√ïES

### Velocidade de Busca

```python
import time

# Teste
query = "Como fazer PIX?"

start = time.time()
resultados = buscar_resposta_similar(query)
end = time.time()

print(f"Tempo: {(end - start)*1000:.2f} ms")
# T√≠pico: 50-200 ms (depende de CPU)
```

**Breakdown**:
```
1. Encoding da pergunta:     ~30-100 ms
2. Similaridade de cosseno:  ~10-50 ms
3. Sorting e filtragem:      ~5-10 ms
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Total:                       ~50-200 ms
```

### Otimiza√ß√µes Aplicadas

**1. Carregar modelo uma vez**:
```python
# ‚ùå Ruim: Carregar a cada requisi√ß√£o
@app.route('/predict', methods=['POST'])
def predict():
    model = SentenceTransformer(...)  # LENTO!
    ...

# ‚úÖ Bom: Carregar na inicializa√ß√£o
model = SentenceTransformer(...)  # Uma vez
@app.route('/predict', methods=['POST'])
def predict():
    # Usar model global
    ...
```

**2. NumPy para embeddings**:
```python
# ‚úÖ R√°pido
embeddings = np.load('embeddings_faq.npy')  # Memmap, lazy loading

# ‚ùå Lento
embeddings = pickle.load(...)  # Carrega tudo na RAM
```

**3. scikit-learn para similaridade**:
```python
from sklearn.metrics.pairwise import cosine_similarity

# ‚úÖ Otimizado (C backend)
sims = cosine_similarity(A, B)

# ‚ùå Lento (Python puro)
sims = np.dot(A, B.T) / (np.linalg.norm(A) * np.linalg.norm(B, axis=1))
```

### Escalabilidade

**Dataset atual**: 1.172 FAQs
```
Mem√≥ria: ~3 MB
Busca:   ~100 ms
```

**Dataset grande**: 100.000 FAQs
```
Mem√≥ria: ~200 MB (embeddings)
Busca:   ~500 ms (similaridade linear em N)

Solu√ß√£o: Usar FAISS para busca aproximada
```

---

## FAISS PARA DATASETS GRANDES

```python
import faiss

# Construir √≠ndice
d = 512  # Dimens√µes
index = faiss.IndexFlatIP(d)  # Inner Product (similar ao cosseno)

# Normalizar embeddings
faiss.normalize_L2(embeddings_perguntas)

# Adicionar ao √≠ndice
index.add(embeddings_perguntas)

# Buscar
k = 3  # Top 3
embedding_query_norm = embedding_query / np.linalg.norm(embedding_query)
D, I = index.search(embedding_query_norm, k)

# D = scores (similaridade)
# I = √≠ndices
```

**Vantagem**: ~10x mais r√°pido para datasets >10k

---

## LIMITA√á√ïES E MELHORIAS

### Limita√ß√µes Atuais

**1. Dom√≠nio Espec√≠fico**:
```python
Query: "Qual a previs√£o do tempo?"
Resultado: Nenhum (threshold n√£o atingido)
‚Üí Sistema s√≥ conhece FAQs banc√°rios
```

**2. Perguntas Muito Gen√©ricas**:
```python
Query: "Como funciona?"
Resultado: V√°rios FAQs com ~40-50% similaridade
‚Üí Amb√≠guo, precisa contexto
```

**3. Termos T√©cnicos Novos**:
```python
Query: "Como usar DeFi no PIX?"
Resultado: Encontra "Como usar PIX" (60%)
‚Üí Modelo n√£o conhece "DeFi"
```

### Melhorias Futuras

**1. Fine-tuning no Dom√≠nio**:
```python
from sentence_transformers import SentenceTransformer, InputExample, losses
from torch.utils.data import DataLoader

# Criar pares positivos (perguntas similares)
train_examples = [
    InputExample(texts=['Como fazer PIX?', 'Como realizar PIX?'], label=1.0),
    InputExample(texts=['O que √© Registrato?', 'Como acessar Registrato?'], label=0.6),
    ...
]

# Treinar
train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)
train_loss = losses.CosineSimilarityLoss(model)

model.fit(
    train_objectives=[(train_dataloader, train_loss)],
    epochs=10
)
```

**2. Reranker (Cross-Encoder)**:
```python
# Bi-encoder (atual): R√°pido, menos preciso
# Cross-encoder: Lento, muito preciso

from sentence_transformers import CrossEncoder

# Primeiro: Bi-encoder para Top 100
candidatos = buscar_resposta_similar(query, top_k=100)

# Depois: Cross-encoder para Top 3
reranker = CrossEncoder('cross-encoder-mmarco-mMiniLMv2-L12-H384-v1')
scores = reranker.predict([(query, c['pergunta']) for c in candidatos])
top3 = np.argsort(scores)[::-1][:3]
```

**3. Feedback do Usu√°rio**:
```html
<!-- resultado.html -->
<button onclick="feedback('util', {{ resultado.id }})">üëç √ötil</button>
<button onclick="feedback('inutil', {{ resultado.id }})">üëé N√£o √∫til</button>
```

```python
# Coletar feedback
# Re-treinar modelo periodicamente
```

---

## FAQ T√âCNICO

**Q: Por que distiluse-base-multilingual e n√£o BERT full?**
A: Distil √© 40% menor, 60% mais r√°pido, com 95% da performance do BERT. Ideal para deployment.

**Q: Como lidar com perguntas em ingl√™s?**
A: Modelo √© multil√≠ngue. Funciona, mas performance pode ser inferior (treinado principalmente em ingl√™s).

**Q: Como adicionar novos FAQs?**
```python
# 1. Adicionar ao dataframe
novo_faq = pd.DataFrame([{
    'pergunta': "Nova pergunta?",
    'resposta': "Nova resposta"
}])
df_faq_limpo = pd.concat([df_faq_limpo, novo_faq])

# 2. Re-gerar embeddings
embeddings_novos = model.encode(df_faq_limpo['pergunta'].tolist())
np.save('embeddings_faq.npy', embeddings_novos)

# 3. Re-salvar dados
with open('dados_faq.pkl', 'wb') as f:
    pickle.dump({...}, f)

# 4. Reiniciar Flask
```

**Q: Como melhorar para perguntas complexas?**
A: Usar retrieval-augmented generation (RAG) com LLM. FAQ retrieval ‚Üí GPT-4 para responder.

---

## TAGS DE BUSCA

`#sentence-transformers` `#busca-semantica` `#embeddings` `#similaridade-cosseno` `#faq` `#flask` `#nlp` `#portuguese-nlp` `#information-retrieval` `#semantic-search`

---

**Vers√£o**: 1.0  
**Compatibilidade**: Python 3.7+, sentence-transformers 2.2+, Flask 2.0+  
**Uso recomendado**: Sistemas de Q&A, chatbots, busca em documenta√ß√£o, autoatendimento
